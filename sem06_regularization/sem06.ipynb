{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Машинное обучение\n",
    "\n",
    "## Факультет математики НИУ ВШЭ\n",
    "\n",
    "### 2019-2020 учебный год\n",
    "\n",
    "Лектор: Илья Щуров\n",
    "\n",
    "Семинаристы: Соня Дымченко, Руслан Хайдуров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# План на сегодня\n",
    "\n",
    "- вокруг да около линейной регрессии\n",
    "- feature selection и регуляризация: теория и практика!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Отбор признаков и регуляризация\n",
    "На лекции мы обсуждали, что в задаче линейной регрессии (и, на самом деле, не только в ней) иногда лучше отбросить какие-то признаки (то есть принудительно установить соответствующую компоненту вектора весов в 0), чтобы уменьшить разброс вектора весов (и получающихся предсказаний) — даже ценой появления смещённости. Это называется «отбор признаков» (feature selection).\n",
    "\n",
    "Сейчас мы поговорим о другом методе уменьшения разброса: регуляризации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 1\n",
    "Пусть, как обычно, $X$ — матрица объект-признак (которую мы считаем фиксированной), $w$ — фиксированный вектор весов (истинный), $y=Xw+\\varepsilon$ — вектор ответов, $\\varepsilon$ — вектор случайных ошибок, $\\mathbb E[\\varepsilon]=0$, ковариацонная матрица $\\varepsilon$ равна $\\sigma^2 I$, где $I$ — тождественная матрица (то есть все компоненты вектора $\\varepsilon$ имеют одинаковую дисперсию $\\sigma^2$, и любая пара разных компонент имеют нулевую ковариацию).\n",
    "\n",
    "Рассмотрим следующиую оптимизационную задачу:\n",
    "\n",
    "$$\\| X\\widehat w - y \\| + \\lambda \\| \\widehat w \\|^2 \\to \\min_{\\widehat w}, \\quad \\lambda > 0.$$\n",
    "\n",
    "Слагаемое $\\lambda \\| \\widehat w \\|^2$ называется *регуляризатором*. Он «штрафует» большие значения компонент $w$.\n",
    "\n",
    "1. Найти её решение в явном виде. \n",
    "2. Что будет, если $\\lambda$ очень большой? Очень маленький?\n",
    "2. Если столбцы матрицы $X$ оказались линейно зависимы, однозначно ли определяется $\\widehat w$?\n",
    "2. Является ли полученная таким образом оценка $\\widehat w$ несмещённой оценкой для $w$?\n",
    "\n",
    "**Замечание.** Регрессия, заданная таким образом, называется *гребнёвой* (ridge) регрессией."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 2\n",
    "Пусть в условиях задачи 1 матрица $X$ имеет вид:\n",
    "\n",
    "$$X=\\begin{pmatrix}\n",
    "10 & 0\\\\\n",
    "-10 & 0\\\\\n",
    "0 & 1\\\\\n",
    "0 & -1\n",
    "\\end{pmatrix}.$$\n",
    "\n",
    "Какая из компонент вектора $w$ сильнее уменьшится в результате добавления регуляризатора? Как вы можете это объяснить? Сравните с обсуждением отбора признаков в этом сюжете."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы поработаем с данными о сообществах в США. Описание датасета:\n",
    "\n",
    "http://archive.ics.uci.edu/ml/datasets/communities+and+crime\n",
    "\n",
    "Датасет на кэггле (в формате .csv):\n",
    "\n",
    "https://www.kaggle.com/kkanda/communities%20and%20crime%20unnormalized%20data%20set\n",
    "\n",
    "Будем предсказывать количество насильственных преступлений относительно численности населения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('crimedata.csv', na_values=[\"?\"])\n",
    "# будем работать не со всеми колонками\n",
    "requiredColumns = [5, 6] + list(range(11,26)) + list(range(32, 103)) + [145]\n",
    "data = data[data.columns[requiredColumns]]\n",
    "# некоторые значения целевой переменной пропущены\n",
    "X = data.loc[data['ViolentCrimesPerPop'].notnull(), :].drop('ViolentCrimesPerPop', axis=1)\n",
    "y = data['ViolentCrimesPerPop'][X.index]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>agePct12t21</th>\n",
       "      <th>agePct12t29</th>\n",
       "      <th>agePct16t24</th>\n",
       "      <th>agePct65up</th>\n",
       "      <th>numbUrban</th>\n",
       "      <th>pctUrban</th>\n",
       "      <th>medIncome</th>\n",
       "      <th>pctWWage</th>\n",
       "      <th>...</th>\n",
       "      <th>MedOwnCostPctInc</th>\n",
       "      <th>MedOwnCostPctIncNoMtg</th>\n",
       "      <th>NumInShelters</th>\n",
       "      <th>NumStreet</th>\n",
       "      <th>PctForeignBorn</th>\n",
       "      <th>PctBornSameState</th>\n",
       "      <th>PctSameHouse85</th>\n",
       "      <th>PctSameCity85</th>\n",
       "      <th>PctSameState85</th>\n",
       "      <th>ViolentCrimesPerPop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11980</td>\n",
       "      <td>3.10</td>\n",
       "      <td>12.47</td>\n",
       "      <td>21.44</td>\n",
       "      <td>10.93</td>\n",
       "      <td>11.33</td>\n",
       "      <td>11980</td>\n",
       "      <td>100.00</td>\n",
       "      <td>75122</td>\n",
       "      <td>89.24</td>\n",
       "      <td>...</td>\n",
       "      <td>21.1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>53.72</td>\n",
       "      <td>65.29</td>\n",
       "      <td>78.09</td>\n",
       "      <td>89.14</td>\n",
       "      <td>41.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23123</td>\n",
       "      <td>2.82</td>\n",
       "      <td>11.01</td>\n",
       "      <td>21.30</td>\n",
       "      <td>10.48</td>\n",
       "      <td>17.18</td>\n",
       "      <td>23123</td>\n",
       "      <td>100.00</td>\n",
       "      <td>47917</td>\n",
       "      <td>78.99</td>\n",
       "      <td>...</td>\n",
       "      <td>20.7</td>\n",
       "      <td>12.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.30</td>\n",
       "      <td>77.17</td>\n",
       "      <td>71.27</td>\n",
       "      <td>90.22</td>\n",
       "      <td>96.12</td>\n",
       "      <td>127.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29344</td>\n",
       "      <td>2.43</td>\n",
       "      <td>11.36</td>\n",
       "      <td>25.88</td>\n",
       "      <td>11.01</td>\n",
       "      <td>10.28</td>\n",
       "      <td>29344</td>\n",
       "      <td>100.00</td>\n",
       "      <td>35669</td>\n",
       "      <td>82.00</td>\n",
       "      <td>...</td>\n",
       "      <td>21.7</td>\n",
       "      <td>11.6</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>44.77</td>\n",
       "      <td>36.60</td>\n",
       "      <td>61.26</td>\n",
       "      <td>82.85</td>\n",
       "      <td>218.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16656</td>\n",
       "      <td>2.40</td>\n",
       "      <td>12.55</td>\n",
       "      <td>25.20</td>\n",
       "      <td>12.19</td>\n",
       "      <td>17.57</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>20580</td>\n",
       "      <td>68.15</td>\n",
       "      <td>...</td>\n",
       "      <td>20.6</td>\n",
       "      <td>14.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.04</td>\n",
       "      <td>88.71</td>\n",
       "      <td>56.70</td>\n",
       "      <td>90.17</td>\n",
       "      <td>96.24</td>\n",
       "      <td>306.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11245</td>\n",
       "      <td>2.76</td>\n",
       "      <td>24.46</td>\n",
       "      <td>40.53</td>\n",
       "      <td>28.69</td>\n",
       "      <td>12.65</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>17390</td>\n",
       "      <td>69.33</td>\n",
       "      <td>...</td>\n",
       "      <td>23.2</td>\n",
       "      <td>12.9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.74</td>\n",
       "      <td>73.75</td>\n",
       "      <td>42.22</td>\n",
       "      <td>60.34</td>\n",
       "      <td>89.02</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2210</th>\n",
       "      <td>56216</td>\n",
       "      <td>3.07</td>\n",
       "      <td>15.46</td>\n",
       "      <td>30.16</td>\n",
       "      <td>14.34</td>\n",
       "      <td>8.08</td>\n",
       "      <td>56216</td>\n",
       "      <td>100.00</td>\n",
       "      <td>24727</td>\n",
       "      <td>75.05</td>\n",
       "      <td>...</td>\n",
       "      <td>22.6</td>\n",
       "      <td>11.7</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>18.90</td>\n",
       "      <td>52.67</td>\n",
       "      <td>39.19</td>\n",
       "      <td>74.58</td>\n",
       "      <td>85.88</td>\n",
       "      <td>545.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2211</th>\n",
       "      <td>12251</td>\n",
       "      <td>2.68</td>\n",
       "      <td>17.36</td>\n",
       "      <td>31.23</td>\n",
       "      <td>16.97</td>\n",
       "      <td>12.57</td>\n",
       "      <td>12251</td>\n",
       "      <td>100.00</td>\n",
       "      <td>20321</td>\n",
       "      <td>75.06</td>\n",
       "      <td>...</td>\n",
       "      <td>17.3</td>\n",
       "      <td>14.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.24</td>\n",
       "      <td>75.16</td>\n",
       "      <td>49.12</td>\n",
       "      <td>78.79</td>\n",
       "      <td>92.85</td>\n",
       "      <td>124.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2212</th>\n",
       "      <td>32824</td>\n",
       "      <td>2.46</td>\n",
       "      <td>11.81</td>\n",
       "      <td>20.96</td>\n",
       "      <td>9.53</td>\n",
       "      <td>20.73</td>\n",
       "      <td>32824</td>\n",
       "      <td>100.00</td>\n",
       "      <td>27182</td>\n",
       "      <td>59.79</td>\n",
       "      <td>...</td>\n",
       "      <td>23.9</td>\n",
       "      <td>13.1</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>7.35</td>\n",
       "      <td>48.66</td>\n",
       "      <td>46.73</td>\n",
       "      <td>75.54</td>\n",
       "      <td>92.30</td>\n",
       "      <td>353.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2213</th>\n",
       "      <td>13547</td>\n",
       "      <td>2.89</td>\n",
       "      <td>17.16</td>\n",
       "      <td>30.01</td>\n",
       "      <td>14.73</td>\n",
       "      <td>10.42</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19899</td>\n",
       "      <td>71.67</td>\n",
       "      <td>...</td>\n",
       "      <td>23.3</td>\n",
       "      <td>14.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.28</td>\n",
       "      <td>82.26</td>\n",
       "      <td>54.05</td>\n",
       "      <td>79.72</td>\n",
       "      <td>94.06</td>\n",
       "      <td>691.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2214</th>\n",
       "      <td>28898</td>\n",
       "      <td>2.61</td>\n",
       "      <td>12.99</td>\n",
       "      <td>25.21</td>\n",
       "      <td>11.63</td>\n",
       "      <td>12.12</td>\n",
       "      <td>28664</td>\n",
       "      <td>99.19</td>\n",
       "      <td>23287</td>\n",
       "      <td>68.89</td>\n",
       "      <td>...</td>\n",
       "      <td>21.2</td>\n",
       "      <td>11.6</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>16.49</td>\n",
       "      <td>55.29</td>\n",
       "      <td>48.74</td>\n",
       "      <td>66.20</td>\n",
       "      <td>89.08</td>\n",
       "      <td>918.89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2215 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      population  householdsize  agePct12t21  agePct12t29  agePct16t24  \\\n",
       "0          11980           3.10        12.47        21.44        10.93   \n",
       "1          23123           2.82        11.01        21.30        10.48   \n",
       "2          29344           2.43        11.36        25.88        11.01   \n",
       "3          16656           2.40        12.55        25.20        12.19   \n",
       "4          11245           2.76        24.46        40.53        28.69   \n",
       "...          ...            ...          ...          ...          ...   \n",
       "2210       56216           3.07        15.46        30.16        14.34   \n",
       "2211       12251           2.68        17.36        31.23        16.97   \n",
       "2212       32824           2.46        11.81        20.96         9.53   \n",
       "2213       13547           2.89        17.16        30.01        14.73   \n",
       "2214       28898           2.61        12.99        25.21        11.63   \n",
       "\n",
       "      agePct65up  numbUrban  pctUrban  medIncome  pctWWage  ...  \\\n",
       "0          11.33      11980    100.00      75122     89.24  ...   \n",
       "1          17.18      23123    100.00      47917     78.99  ...   \n",
       "2          10.28      29344    100.00      35669     82.00  ...   \n",
       "3          17.57          0      0.00      20580     68.15  ...   \n",
       "4          12.65          0      0.00      17390     69.33  ...   \n",
       "...          ...        ...       ...        ...       ...  ...   \n",
       "2210        8.08      56216    100.00      24727     75.05  ...   \n",
       "2211       12.57      12251    100.00      20321     75.06  ...   \n",
       "2212       20.73      32824    100.00      27182     59.79  ...   \n",
       "2213       10.42          0      0.00      19899     71.67  ...   \n",
       "2214       12.12      28664     99.19      23287     68.89  ...   \n",
       "\n",
       "      MedOwnCostPctInc  MedOwnCostPctIncNoMtg  NumInShelters  NumStreet  \\\n",
       "0                 21.1                   14.0             11          0   \n",
       "1                 20.7                   12.5              0          0   \n",
       "2                 21.7                   11.6             16          0   \n",
       "3                 20.6                   14.5              0          0   \n",
       "4                 23.2                   12.9              2          0   \n",
       "...                ...                    ...            ...        ...   \n",
       "2210              22.6                   11.7             64          0   \n",
       "2211              17.3                   14.4              0          0   \n",
       "2212              23.9                   13.1             44          0   \n",
       "2213              23.3                   14.1              0          0   \n",
       "2214              21.2                   11.6             10          2   \n",
       "\n",
       "      PctForeignBorn  PctBornSameState  PctSameHouse85  PctSameCity85  \\\n",
       "0              10.66             53.72           65.29          78.09   \n",
       "1               8.30             77.17           71.27          90.22   \n",
       "2               5.00             44.77           36.60          61.26   \n",
       "3               2.04             88.71           56.70          90.17   \n",
       "4               1.74             73.75           42.22          60.34   \n",
       "...              ...               ...             ...            ...   \n",
       "2210           18.90             52.67           39.19          74.58   \n",
       "2211            2.24             75.16           49.12          78.79   \n",
       "2212            7.35             48.66           46.73          75.54   \n",
       "2213            2.28             82.26           54.05          79.72   \n",
       "2214           16.49             55.29           48.74          66.20   \n",
       "\n",
       "      PctSameState85  ViolentCrimesPerPop  \n",
       "0              89.14                41.02  \n",
       "1              96.12               127.56  \n",
       "2              82.85               218.59  \n",
       "3              96.24               306.64  \n",
       "4              89.02                  NaN  \n",
       "...              ...                  ...  \n",
       "2210           85.88               545.75  \n",
       "2211           92.85               124.10  \n",
       "2212           92.30               353.83  \n",
       "2213           94.06               691.17  \n",
       "2214           89.08               918.89  \n",
       "\n",
       "[2215 rows x 89 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите линейную регрессию и выведите качество по метрикам $R^2$ и MSE на обучающей и тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавьте регуляризатор и посмотрите, изменилось ли качество. Попробуйте методы Lasso ($L_1$) и Ridge ($L_2$). Попробуйте также KNN.\n",
    "\n",
    "**Комментарий.** $L_1$-регуляризатор — это просто $L_1$-норма вектора весов, то есть сумма модулей всех компонент."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуйте поизменять параметр регуляризации ($\\lambda$) и посмотреть, что получится. Что будет с происходить с коэффициентами регрессии при увеличении параметра регуляризации?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А что изменится при нормировании признаков? Попробуйте StandardScaler и MinMaxScaler. Есть ли разница? Влияет ли нормирование на предсказания линейной регрессии? А на предсказания регуляризованной? Почему так?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 High/low variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полезны ли признаки, имеющие высокую дисперсию? А низкую? Попробуйте удалить их и посмотреть, как изменится качество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_variance = X_train.var().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуйте теперь избавиться от самых коррелирующих признаков и посмотрите на изменение качества."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correlated_features = X.corr(method='pearson').abs().unstack().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 Сombination!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скомбинируйте нормализацию с выбором признаков и посмотрите, изменилось ли качество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какой метод обработки данных сработал лучше всех? Используя его, подберите параметр регуляризации и посмотрите на финальное качество!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
